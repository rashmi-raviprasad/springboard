{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatPic:\n",
    "    def __init__(self, name):\n",
    "        '''\n",
    "        Initializes CatPic class with the cat's 'name' (a portion of the filename)\n",
    "        '''\n",
    "        self.name = name\n",
    "        \n",
    "    def add_image(self, filename):\n",
    "        '''\n",
    "        Assigns image to CatPic from file\n",
    "        '''\n",
    "        img = cv2.imread(filename)\n",
    "        self.rows, self.cols = img.shape[:2]\n",
    "        self.image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    def add_coords(self, coord_dict):\n",
    "        '''\n",
    "        Assigns annotations to CatPic from dict of coordinates taken from file\n",
    "        '''\n",
    "        self.x_l_eye = coord_dict['x_l_eye']\n",
    "        self.y_l_eye = coord_dict['y_l_eye']\n",
    "        self.x_r_eye = coord_dict['x_r_eye']\n",
    "        self.y_r_eye = coord_dict['y_r_eye']\n",
    "        self.x_mouth = coord_dict['x_mouth']\n",
    "        self.y_mouth = coord_dict['y_mouth']\n",
    "        self.x_l_ear1 = coord_dict['x_l_ear1']\n",
    "        self.y_l_ear1 = coord_dict['y_l_ear1']\n",
    "        self.x_l_ear2 = coord_dict['x_l_ear2']\n",
    "        self.y_l_ear2 = coord_dict['y_l_ear2']\n",
    "        self.x_l_ear3 = coord_dict['x_l_ear3']\n",
    "        self.y_l_ear3 = coord_dict['y_l_ear3']\n",
    "        self.x_r_ear1 = coord_dict['x_r_ear1']\n",
    "        self.y_r_ear1 = coord_dict['y_r_ear1']\n",
    "        self.x_r_ear2 = coord_dict['x_r_ear2']\n",
    "        self.y_r_ear2 = coord_dict['y_r_ear2']\n",
    "        self.x_r_ear3 = coord_dict['x_r_ear3']\n",
    "        self.y_r_ear3 = coord_dict['y_r_ear3']\n",
    "    \n",
    "    def rotate_point(self, x, y):\n",
    "        '''\n",
    "        Rotates point by specified angle about specified point\n",
    "        '''\n",
    "        c_x, c_y = self.rotation_center\n",
    "        rad = np.deg2rad(self.theta)\n",
    "        new_x = c_x + np.cos(rad) * (x - c_x) + np.sin(rad) * (y - c_y)\n",
    "        new_y = c_y + -np.sin(rad) * (x - c_x) + np.cos(rad) * (y - c_y)\n",
    "        return new_x, new_y\n",
    "        \n",
    "    def transform(self, flip=False):\n",
    "        '''\n",
    "        Flips image & annotation coordinates if rotation angle is negative, \n",
    "        then rotates image & annotation coordinates by rotation angle so that\n",
    "        cat's eyes are parallel\n",
    "        '''\n",
    "        if flip:\n",
    "            self.flip_image = cv2.flip(self.image, 1)\n",
    "            self.flip_x_l_eye = self.cols - self.x_l_eye\n",
    "            self.flip_x_r_eye = self.cols - self.x_r_eye\n",
    "            self.flip_x_mouth = self.cols - self.x_mouth\n",
    "            self.flip_x_l_ear1 = self.cols - self.x_l_ear1\n",
    "            self.flip_x_l_ear2 = self.cols - self.x_l_ear2\n",
    "            self.flip_x_l_ear3 = self.cols - self.x_l_ear3\n",
    "            self.flip_x_r_ear1 = self.cols - self.x_r_ear1\n",
    "            self.flip_x_r_ear2 = self.cols - self.x_r_ear2\n",
    "            self.flip_x_r_ear3 = self.cols - self.x_r_ear3\n",
    "            \n",
    "            eye_slope = (self.y_l_eye - self.y_r_eye) / (self.flip_x_l_eye - self.flip_x_r_eye)\n",
    "            self.theta = np.rad2deg(np.arctan(eye_slope))\n",
    "            self.rotation_center = ((self.y_l_eye + self.y_r_eye)/2, (self.flip_x_l_eye + self.flip_x_r_eye)/2)\n",
    "            M = cv2.getRotationMatrix2D(self.rotation_center, self.theta, scale=1)\n",
    "            self.rot_image = cv2.warpAffine(self.flip_image, M, (self.cols, self.rows))\n",
    "            self.rot_x_l_eye, self.rot_y_l_eye = self.rotate_point(self.flip_x_l_eye, self.y_l_eye)\n",
    "            self.rot_x_r_eye, self.rot_y_r_eye = self.rotate_point(self.flip_x_r_eye, self.y_r_eye)\n",
    "            self.rot_x_mouth, self.rot_y_mouth = self.rotate_point(self.flip_x_mouth, self.y_mouth)\n",
    "            self.rot_x_l_ear1, self.rot_y_l_ear1 = self.rotate_point(self.flip_x_l_ear1, self.y_l_ear1)\n",
    "            self.rot_x_l_ear2, self.rot_y_l_ear2 = self.rotate_point(self.flip_x_l_ear2, self.y_l_ear2)\n",
    "            self.rot_x_l_ear3, self.rot_y_l_ear3 = self.rotate_point(self.flip_x_l_ear3, self.y_l_ear3)\n",
    "            self.rot_x_r_ear1, self.rot_y_r_ear1 = self.rotate_point(self.flip_x_r_ear1, self.y_r_ear1)\n",
    "            self.rot_x_r_ear2, self.rot_y_r_ear2 = self.rotate_point(self.flip_x_r_ear2, self.y_r_ear2)\n",
    "            self.rot_x_r_ear3, self.rot_y_r_ear3 = self.rotate_point(self.flip_x_r_ear3, self.y_r_ear3)\n",
    "        \n",
    "        else:\n",
    "            eye_slope = (self.y_l_eye - self.y_r_eye) / (self.x_l_eye - self.x_r_eye)\n",
    "            self.theta = np.rad2deg(np.arctan(eye_slope))\n",
    "            self.rotation_center = ((self.y_l_eye + self.y_r_eye)/2, (self.x_l_eye + self.x_r_eye)/2)\n",
    "            M = cv2.getRotationMatrix2D(self.rotation_center, self.theta, scale=1)\n",
    "            self.rot_image = cv2.warpAffine(self.image, M, (self.cols, self.rows))\n",
    "            self.rot_x_l_eye, self.rot_y_l_eye = self.rotate_point(self.x_l_eye, self.y_l_eye)\n",
    "            self.rot_x_r_eye, self.rot_y_r_eye = self.rotate_point(self.x_r_eye, self.y_r_eye)\n",
    "            self.rot_x_mouth, self.rot_y_mouth = self.rotate_point(self.x_mouth, self.y_mouth)\n",
    "            self.rot_x_l_ear1, self.rot_y_l_ear1 = self.rotate_point(self.x_l_ear1, self.y_l_ear1)\n",
    "            self.rot_x_l_ear2, self.rot_y_l_ear2 = self.rotate_point(self.x_l_ear2, self.y_l_ear2)\n",
    "            self.rot_x_l_ear3, self.rot_y_l_ear3 = self.rotate_point(self.x_l_ear3, self.y_l_ear3)\n",
    "            self.rot_x_r_ear1, self.rot_y_r_ear1 = self.rotate_point(self.x_r_ear1, self.y_r_ear1)\n",
    "            self.rot_x_r_ear2, self.rot_y_r_ear2 = self.rotate_point(self.x_r_ear2, self.y_r_ear2)\n",
    "            self.rot_x_r_ear3, self.rot_y_r_ear3 = self.rotate_point(self.x_r_ear3, self.y_r_ear3)\n",
    "        \n",
    "    def crop_w_border(self):\n",
    "        '''\n",
    "        Defines bounding box containing cat's face and crops image.\n",
    "        Pads image first if bounding box is out of range\n",
    "        '''\n",
    "        rot_rows, rot_cols = self.rot_image.shape[:2]\n",
    "        ear_mouth_height = self.rot_y_mouth - min([self.rot_y_l_ear2, self.rot_y_r_ear2])\n",
    "        bbox_y_min = int(min([self.rot_y_l_ear2, self.rot_y_r_ear2]) - 0.1 * ear_mouth_height)\n",
    "        bbox_y_max = int(self.rot_y_mouth + 0.2 * ear_mouth_height)\n",
    "        bbox_size = bbox_y_max - bbox_y_min\n",
    "        vert_center = 0.5 * (self.rot_x_l_ear2 + self.rot_x_r_ear2)\n",
    "        bbox_x_min = int(vert_center - 0.5 * bbox_size)\n",
    "        bbox_x_max = int(vert_center + 0.5 * bbox_size)\n",
    "        padding = [0]\n",
    "        if bbox_y_min < 0:\n",
    "            padding.append(abs(bbox_y_min))\n",
    "        if bbox_x_min < 0:\n",
    "            padding.append(abs(bbox_x_min))\n",
    "        if bbox_y_max > rot_rows:\n",
    "            padding.append(bbox_y_max - rot_rows)\n",
    "        if bbox_x_max > rot_cols:\n",
    "            padding.append(bbox_x_max - rot_cols)\n",
    "        \n",
    "        max_padding = max(padding)\n",
    "        padding_color = [0, 0, 0]\n",
    "        pad_image = cv2.copyMakeBorder(self.rot_image, max_padding, max_padding, max_padding, max_padding,\n",
    "                                      cv2.BORDER_CONSTANT, value=padding_color)\n",
    "        \n",
    "        new_y_min, new_y_max = bbox_y_min + max_padding, bbox_y_max + max_padding\n",
    "        new_x_min, new_x_max = bbox_x_min + max_padding, bbox_x_max + max_padding\n",
    "        self.cropped_image = pad_image[new_y_min:new_y_max, new_x_min:new_x_max]\n",
    "        \n",
    "        \n",
    "    def show_orig(self, show_points=False):\n",
    "        '''\n",
    "        Displays raw image with option of showing raw annotations\n",
    "        '''\n",
    "        plt.imshow(self.image)\n",
    "        if show_points:\n",
    "            plt.plot(self.x_l_eye, self.y_l_eye, 'bo')\n",
    "            plt.plot(self.x_r_eye, self.y_r_eye, 'bo')\n",
    "            plt.plot(self.x_mouth, self.y_mouth, 'bo')\n",
    "            plt.plot(self.x_l_ear1, self.y_l_ear1, 'bo')\n",
    "            plt.plot(self.x_l_ear2, self.y_l_ear2, 'bo')\n",
    "            plt.plot(self.x_l_ear3, self.y_l_ear3, 'bo')\n",
    "            plt.plot(self.x_r_ear1, self.y_r_ear1, 'bo')\n",
    "            plt.plot(self.x_r_ear2, self.y_r_ear2, 'bo')\n",
    "            plt.plot(self.x_r_ear3, self.y_r_ear3, 'bo')\n",
    "        plt.title('Orig Cat # ' + self.name)\n",
    "    \n",
    "    def plot_pic(self, show_points=False):\n",
    "        '''\n",
    "        Displays processed image with option of showing rotated annotations\n",
    "        '''\n",
    "        plt.imshow(self.cropped_image)\n",
    "        if show_points:\n",
    "            plt.plot(self.rot_x_l_eye, self.rot_y_l_eye, 'bo')\n",
    "            plt.plot(self.rot_x_r_eye, self.rot_y_r_eye, 'bo')\n",
    "            plt.plot(self.rot_x_mouth, self.rot_y_mouth, 'bo')\n",
    "            plt.plot(self.rot_x_l_ear1, self.rot_y_l_ear1, 'bo')\n",
    "            plt.plot(self.rot_x_l_ear2, self.rot_y_l_ear2, 'bo')\n",
    "            plt.plot(self.rot_x_l_ear3, self.rot_y_l_ear3, 'bo')\n",
    "            plt.plot(self.rot_x_r_ear1, self.rot_y_r_ear1, 'bo')\n",
    "            plt.plot(self.rot_x_r_ear2, self.rot_y_r_ear2, 'bo')\n",
    "            plt.plot(self.rot_x_r_ear3, self.rot_y_r_ear3, 'bo')\n",
    "        plt.title('Processed Cat # ' + self.name)\n",
    "        \n",
    "    def save_to_file(self, directory):\n",
    "        '''\n",
    "        Saves processed image to file in jpg format\n",
    "        '''\n",
    "        filename = directory + self.name + '.jpg'\n",
    "        cv2.imwrite(filename, cv2.cvtColor(self.cropped_image, cv2.COLOR_RGB2BGR))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_DIR = 'cat_dataset/preprocessing_test/'\n",
    "files = []\n",
    "for file in os.listdir(FILE_DIR):\n",
    "    if file.endswith('.jpg'):\n",
    "        files.append(file)\n",
    "\n",
    "\n",
    "names = [f.split('.')[-2][4:] for f in files]\n",
    "pic_dict = {}\n",
    "coord_list = ['x_l_eye', 'y_l_eye', 'x_r_eye', 'y_r_eye', 'x_mouth', 'y_mouth',\n",
    "             'x_l_ear1', 'y_l_ear1', 'x_l_ear2', 'y_l_ear2', 'x_l_ear3', 'y_l_ear3',\n",
    "             'x_r_ear1', 'y_r_ear1', 'x_r_ear2', 'y_r_ear2', 'x_r_ear3', 'y_r_ear3']\n",
    "\n",
    "for i, f in enumerate(files):\n",
    "    pic = CatPic(names[i])\n",
    "    pic.add_image(FILE_DIR + f)\n",
    "    with open(FILE_DIR + f + '.cat') as annotation_file:\n",
    "        for line in annotation_file:\n",
    "            coord_vals = [int(l) for l in line.split()[1:]]\n",
    "            coord_dict = dict(zip(coord_list, coord_vals))\n",
    "            pic.add_coords(coord_dict)\n",
    "    pic_dict[names[i]] = pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_dataset/CAT_00/\n"
     ]
    }
   ],
   "source": [
    "FILE_DIR = 'cat_dataset/'\n",
    "files = []\n",
    "for file in os.listdir(FILE_DIR):\n",
    "    if file.startswith('CAT'):\n",
    "        files.append(file)\n",
    "\n",
    "print(FILE_DIR + files[0] + '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
